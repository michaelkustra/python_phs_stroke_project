---
title: "R Notebook"
output: html_notebook
---

```{python}
import pandas as pd
from pyprojroot import here
```

```{r}
library(reticulate)
library(tidyverse)
# py_install("pandas-profiling")
# py_install("scikit-learn")
# py_install("scikit-plot")
# py_install("matplotlib")
```

```{python}
# model packages
import pandas_profiling
```

```{python}
# read in mortality data
hb_mortality = pd.read_csv(here("raw_data/stroke_mortalitybyhbr.csv"))
ca_mortality = pd.read_csv(here("raw_data/stroke_mortalitybyca.csv"))
```

```{r}
hb_mortality <- py$hb_mortality %>% 
  janitor::clean_names()
```

```{python}
# clean data by removing unnecessary columns and values
hb_mortality_reduced = r.hb_mortality.drop(columns = ['hbrqf', 'age_group_qf', 'sex_qf', 'number_of_deaths_qf', 'crude_rate_qf'])

hb_mortality_reduced = hb_mortality_reduced.query('age_group != "All" & sex != "All" & hbr != "S92000003"').dropna()
```

```{python}
# assign categorical vars dummies
hb_mortality_reduced = pd.get_dummies(hb_mortality_reduced, drop_first = True)

hb_mortality_reduced.head()
```

```{python}
# set our response array 
response_var = hb_mortality_reduced['number_of_deaths']
# put our predictors in a data frame
predictor_vars = hb_mortality_reduced.drop(columns = 'number_of_deaths')
```

```{python}
# create train / test split
from sklearn.model_selection import train_test_split

mortality_pred_train, mortality_pred_test, mortality_resp_train, mortality_resp_test = (
    train_test_split(
        predictor_vars, 
        response_var, 
        test_size = 0.1
    )
)
```


```{python}
# define model using train data
from sklearn.linear_model import LinearRegression
mortality_model = LinearRegression()

mortality_model.fit(mortality_pred_train, mortality_resp_train)
```

```{python}
# check r-squared value of current model
from sklearn.model_selection import cross_val_score
mortality_model.score(mortality_pred_train, mortality_resp_train)

# r-squared scores for each fold
scores = cross_val_score(
    mortality_model, mortality_pred_train, mortality_resp_train, scoring='r2', cv=10
)
scores

```

```{python}
import numpy as np

print(mortality_model.score(mortality_pred_train, mortality_resp_train))

# mean score of all models
print(np.mean(scores))
```

```{python}
# feature importance by matching predictors to coefficients in a df
pd.DataFrame({
    'Variable':predictor_vars.columns,
    'Coefficients':mortality_model.coef_
})
```

```{python}
import statsmodels.api as sm

# add in the constant to the data
predictor_vars = sm.add_constant(predictor_vars)
predictor_vars.head()
```

```{python}
# model summary using statsmodels
sm_model = sm.OLS(response_var, predictor_vars).fit()
print(sm_model.summary())
```

__Interpretation__

From this summary it seems that the predictors of `year` and `sex` could be 
removed from the next model iteration due to their large p-values. May also
prove useful to group the statistically insiginifcant health boards together
to see if that group would be significant to my model or not.


```{python}
# model score on test data
mortality_model.score(mortality_pred_test, mortality_resp_test)
```



```{python}
# Regression Learning Curve
import matplotlib.pyplot as plt
import scikitplot as skplt

skplt.estimators.plot_learning_curve(LinearRegression(), predictor_vars, response_var,
                                     cv =7, shuffle =True, scoring ="r2", n_jobs =-1,
                                     figsize =(6,4), title_fontsize ="large", text_fontsize ="medium",
                                     title ="Regression Learning Curve")
                                     
plt.show()
```
